{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8GVdqSaqbGer"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iI6rSx22bQC4"},"outputs":[],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4MMXB-TMdA-n"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"23TOba33L4qf"},"outputs":[],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"auBUD2Gacd0V"},"outputs":[],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"156xcB9nCl5lbNZczC6n2bvBQDZ0uBUqs"},"executionInfo":{"elapsed":8042052,"status":"aborted","timestamp":1668314333372,"user":{"displayName":"jamal Alasadi","userId":"04565293417501620049"},"user_tz":300},"id":"77xg7JEibYTo","outputId":"72076d64-9545-4f44-a941-36c84b878c45"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["!7z e \"/content/drive/My Drive/celeba_png/img_align_celeba_png.7z.001\" -o\"/content/img/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":8042047,"status":"aborted","timestamp":1668314333373,"user":{"displayName":"jamal Alasadi","userId":"04565293417501620049"},"user_tz":300},"id":"sdwDa2UCbcwE","outputId":"c006e027-d492-47f7-ffca-eca7a888ec46"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-f8261c772fa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mcele_attrib_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\s+\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# lfw = cele_attrib.set_index('SUBJECT_ID')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m#cele_attrib_male = pd.read_csv(file_path_test_male,delimiter = \"\\s+\",names = columns)# lfw = cele_attrib.set_index('SUBJECT_ID')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mcele_attrib_female\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path_test_female\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\s+\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# lfw = cele_attrib.set_index('SUBJECT_ID')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mval_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'file_path_test_female' is not defined"]}],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import sklearn.metrics as mt\n","from skimage import io, transform\n","\n","\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","\n","# additional files is located in /home/jamal/Downloads/additional_files/\n","def save_checkpoint_high(state, filename='/content/drive/MyDrive/vre_autoencoder_final/trained_modes_final/checkpoint_propose_Male_celeb_high.pth.tar'):\n","    torch.save(state, filename)\n","def save_checkpoint_low(state, filename='/content/drive/MyDrive/vre_autoencoder_final/trained_modes_final/checkpoint_propose_Male_celeb_low.pth.tar'):\n","    torch.save(state, filename)\n","def save_checkpoint_class_MF(state, filename='/content/drive/MyDrive/vre_autoencoder_final/trained_modes_final/checkpoint_classification_propose_MF.pth.tar'):\n","    torch.save(state, filename)\n","def save_checkpoint_class_SD(state, filename='/content/drive/MyDrive/vre_autoencoder_final/trained_modes_final/checkpoint_classification_propose_SD.pth.tar'):\n","    torch.save(state, filename)\n","def save_checkpoint_class_YO(state, filename='/content/drive/MyDrive/vre_autoencoder_final/trained_modes_final/checkpoint_classification_propose_YO.pth.tar'):\n","    torch.save(state, filename)\n","\n","file_path_all ='/content/drive/MyDrive/list_attr_celeba_M.txt'\n","\n","file_path ='/content/drive/MyDrive/list_attr_celeba_train.txt'\n","#file_path_test_male ='/content/drive/MyDrive/list_attr_celeba_test_male.txt'\n","\n","#file_path_test_female ='/content/drive/MyDrive/list_attr_celeba_test_female.txt'\n","\n","\n","\n","images_path = '/content/img/' #train\n","\n","load_net = 0\n","\n","columns = ['ImgId','5_o_Clock_Shadow',\n","           ' Arched_Eyebrows', 'Attractive',\n","           'Bags_Under_Eyes', 'Bald', 'Bangs',\n","           'Big_Lips', 'Big_Nose', 'Black_Hair',\n","           'Blond_Hair', 'Blurry', 'Brown_Hair',\n","           'Bushy_Eyebrows', 'Chubby', 'Double_Chin',\n","           'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup',\n","           'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', 'Mustache',\n","           'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin', 'Pointy_Nose',\n","           'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair',\n","           'Wavy_Hair', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young']\n","\n","\n","cele_attrib = pd.read_csv(file_path,delimiter = \"\\s+\",names = columns)# lfw = cele_attrib.set_index('SUBJECT_ID')\n","\n","cele_attrib_all = pd.read_csv(file_path_all,delimiter = \"\\s+\",names = columns)# lfw = cele_attrib.set_index('SUBJECT_ID')\n","#cele_attrib_male = pd.read_csv(file_path_test_male,delimiter = \"\\s+\",names = columns)# lfw = cele_attrib.set_index('SUBJECT_ID')\n","cele_attrib_female = pd.read_csv(file_path_test_female,delimiter = \"\\s+\",names = columns)# lfw = cele_attrib.set_index('SUBJECT_ID')\n","\n","val_ratio = .2;\n","tmp_train_lst = cele_attrib['ImgId'].tolist()\n","train_lst = [int(tmp_train_lst[i].split('.')[0]) for i in range(len(tmp_train_lst))]\n","index             = train_lst\n","train_data_length = int(len(index)*.8)\n","val_data_length   = int(val_ratio*len(index))\n","\n","\n","#tmp_test_lst = cele_attrib_male['ImgId'].tolist()\n","tmp_test_lst = cele_attrib_female['ImgId'].tolist()\n","\n","test_lst = [int(tmp_test_lst[i].split('.')[0]) for i in range(len(tmp_test_lst))]\n","test_index             = test_lst\n","test_data_length = len(test_index)\n","\n","val_index         = index[train_data_length:(train_data_length+val_data_length)]\n","\n","#lfw = cele_attrib\n","\n","\n","import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","\n","class VAE(nn.Module):\n","    def __init__(self, nc, ngf, ndf, latent_variable_size):\n","        super(VAE, self).__init__()\n","\n","        self.nc = nc\n","        self.ngf = ngf\n","        self.ndf = ndf\n","        self.latent_variable_size = latent_variable_size\n","\n","        # encoder\n","        self.e1 = nn.Conv2d(nc, self.ndf, 4, 2, 1)\n","        self.bn1 = nn.BatchNorm2d(self.ndf)\n","\n","        self.e2 = nn.Conv2d(self.ndf, self.ndf*2, 4, 2, 1)\n","        self.bn2 = nn.BatchNorm2d(self.ndf*2)\n","\n","        self.e3 = nn.Conv2d(ndf*2, ndf*4, 4, 2, 1)\n","        self.bn3 = nn.BatchNorm2d(ndf*4)\n","\n","        self.e4 = nn.Conv2d(ndf*4, ndf*8, 4, 2, 1)\n","        self.bn4 = nn.BatchNorm2d(ndf*8)\n","\n","        self.e5 = nn.Conv2d(ndf*8, ndf*8, 4, 2, 1)\n","        self.bn5 = nn.BatchNorm2d(ndf*8)\n","\n","        self.fc1 = nn.Linear(ndf*8*4*4, latent_variable_size)\n","        self.fc2 = nn.Linear(ndf*8*4*4, latent_variable_size)\n","\n","        # decoder\n","        self.d1 = nn.Linear(latent_variable_size, self.ngf*8*2*4*4)\n","\n","        self.up1 = nn.UpsamplingNearest2d(scale_factor=2)\n","        self.pd1 = nn.ReplicationPad2d(1)\n","        self.d2 = nn.Conv2d(self.ngf*8*2, self.ngf*8, 3, 1)\n","        self.bn6 = nn.BatchNorm2d(self.ngf*8, 1.e-3)\n","\n","        self.up2 = nn.UpsamplingNearest2d(scale_factor=2)\n","        self.pd2 = nn.ReplicationPad2d(1)\n","        self.d3 = nn.Conv2d(self.ngf*8, self.ngf*4, 3, 1)\n","        self.bn7 = nn.BatchNorm2d(self.ngf*4, 1.e-3)\n","\n","        self.up3 = nn.UpsamplingNearest2d(scale_factor=2)\n","        self.pd3 = nn.ReplicationPad2d(1)\n","        self.d4 = nn.Conv2d(self.ngf*4, self.ngf*2, 3, 1)\n","        self.bn8 = nn.BatchNorm2d(self.ngf*2, 1.e-3)\n","\n","        self.up4 = nn.UpsamplingNearest2d(scale_factor=2)\n","        self.pd4 = nn.ReplicationPad2d(1)\n","        self.d5 = nn.Conv2d(self.ngf*2, self.ngf, 3, 1)\n","        self.bn9 = nn.BatchNorm2d(self.ngf, 1.e-3)\n","\n","        self.up5 = nn.UpsamplingNearest2d(scale_factor=2)\n","        self.pd5 = nn.ReplicationPad2d(1)\n","        self.d6 = nn.Conv2d(self.ngf, nc, 3, 1)\n","\n","        self.leakyrelu = nn.LeakyReLU(0.2)\n","        self.relu = nn.ReLU()\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def encode(self, x):\n","        h1 = self.leakyrelu(self.bn1(self.e1(x)))\n","        h2 = self.leakyrelu(self.bn2(self.e2(h1)))\n","        h3 = self.leakyrelu(self.bn3(self.e3(h2)))\n","        h4 = self.leakyrelu(self.bn4(self.e4(h3)))\n","        h5 = self.leakyrelu(self.bn5(self.e5(h4)))\n","        h5 = h5.view(-1, self.ndf*8*4*4)\n","\n","        return self.fc1(h5), self.fc2(h5), h5\n","\n","    def reparametrize(self, mu, logvar):\n","        std = logvar.mul(0.5).exp_()\n","        if use_cuda:\n","            eps = torch.cuda.FloatTensor(std.size()).normal_()\n","        else:\n","            eps = torch.FloatTensor(std.size()).normal_()\n","        eps = Variable(eps)\n","        return eps.mul(std).add_(mu)\n","\n","    def decode(self, z):\n","        h1 = self.relu(self.d1(z))\n","        h1 = h1.view(-1, self.ngf*8*2, 4, 4)\n","        h2 = self.leakyrelu(self.bn6(self.d2(self.pd1(self.up1(h1)))))\n","        h3 = self.leakyrelu(self.bn7(self.d3(self.pd2(self.up2(h2)))))\n","        h4 = self.leakyrelu(self.bn8(self.d4(self.pd3(self.up3(h3)))))\n","        h5 = self.leakyrelu(self.bn9(self.d5(self.pd4(self.up4(h4)))))\n","\n","        return self.sigmoid(self.d6(self.pd5(self.up5(h5))))\n","\n","    def get_latent_var(self, x):\n","        mu, logvar, h1 = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n","        z = self.reparametrize(mu, logvar)\n","        return z\n","\n","    def forward(self, x):\n","        mu, logvar,h2 = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n","        z = self.reparametrize(mu, logvar)\n","        res = self.decode(z)\n","        return res, mu, logvar, h2\n","\n","\n","class VAE_low(nn.Module):\n","    def __init__(self, nc, ngf, ndf, latent_variable_size):\n","        super(VAE_low, self).__init__()\n","\n","        self.nc = nc\n","        self.ngf = ngf\n","        self.ndf = ndf\n","        self.latent_variable_size = latent_variable_size\n","\n","        # encoder\n","        self.e1 = nn.Conv2d(nc, self.ndf, 4, 2, 1)\n","        self.bn1 = nn.BatchNorm2d(self.ndf)\n","\n","        self.e2 = nn.Conv2d(self.ndf, self.ndf*2, 4, 2, 1)\n","        self.bn2 = nn.BatchNorm2d(self.ndf*2)\n","\n","        self.e3 = nn.Conv2d(ndf*2, ndf*4, 4, 2, 1)\n","        self.bn3 = nn.BatchNorm2d(ndf*4)\n","        #\n","        # self.e4 = nn.Conv2d(ndf*4, ndf*4, 4, 2, 1)\n","        # self.bn4 = nn.BatchNorm2d(ndf*4)\n","\n","        # self.e5 = nn.Conv2d(ndf*8, ndf*8, 4, 2, 1)\n","        # self.bn5 = nn.BatchNorm2d(ndf*8)\n","\n","        self.fc1 = nn.Linear(ndf*4*4, latent_variable_size)\n","        self.fc2 = nn.Linear(ndf*4*4, latent_variable_size)\n","\n","        # decoder\n","        self.d1 = nn.Linear(latent_variable_size, ngf*4*4)\n","\n","        self.up1 = nn.UpsamplingNearest2d(scale_factor=2)\n","        self.pd1 = nn.ReplicationPad2d(1)\n","        self.d2 = nn.Conv2d(self.ngf, self.ngf//2, 3, 1)\n","        self.bn6 = nn.BatchNorm2d(self.ngf//2, 1.e-3)\n","\n","        self.up2 = nn.UpsamplingNearest2d(scale_factor=2)\n","        self.pd2 = nn.ReplicationPad2d(1)\n","        self.d3 = nn.Conv2d(self.ngf, self.ngf//2, 3, 1)\n","        self.bn7 = nn.BatchNorm2d(self.ngf//2, 1.e-3)\n","\n","        self.up3 = nn.UpsamplingNearest2d(scale_factor=2)\n","        self.pd3 = nn.ReplicationPad2d(1)\n","        self.d4 = nn.Conv2d(self.ngf*4, self.ngf*2, 3, 1)\n","        self.bn8 = nn.BatchNorm2d(self.ngf*2, 1.e-3)\n","\n","        self.up4 = nn.UpsamplingNearest2d(scale_factor=2)\n","        self.pd4 = nn.ReplicationPad2d(1)\n","        self.d5 = nn.Conv2d(self.ngf*2, self.ngf, 3, 1)\n","        self.bn9 = nn.BatchNorm2d(self.ngf, 1.e-3)\n","\n","        self.up5 = nn.UpsamplingNearest2d(scale_factor=2)\n","        self.pd5 = nn.ReplicationPad2d(1)\n","        self.d6 = nn.Conv2d(self.ngf//2, nc, 3, 1)\n","\n","        self.leakyrelu = nn.LeakyReLU(0.2)\n","        self.relu = nn.ReLU()\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def encode(self, x):\n","        h1 = self.leakyrelu(self.bn1(self.e1(x)))\n","        h2 = self.leakyrelu(self.bn2(self.e2(h1)))\n","        h3 = self.leakyrelu(self.bn3(self.e3(h2)))\n","        # h4 = self.leakyrelu(self.bn4(self.e4(h3)))\n","        # h5 = self.leakyrelu(self.bn5(self.e5(h4)))\n","        h5 = h3.view(-1, self.ndf*4*4)\n","\n","        return self.fc1(h5), self.fc2(h5),h5\n","\n","    def reparametrize(self, mu, logvar):\n","        std = logvar.mul(0.5).exp_()\n","        if use_cuda:\n","            eps = torch.cuda.FloatTensor(std.size()).normal_()\n","        else:\n","            eps = torch.FloatTensor(std.size()).normal_()\n","        eps = Variable(eps)\n","        return eps.mul(std).add_(mu)\n","\n","    def decode(self, z):\n","        h1 = self.relu(self.d1(z))\n","        h1 = h1.view(-1, self.ngf, 4, 4)\n","        h2 = self.leakyrelu(self.bn6(self.d2(self.pd1(self.up1(h1)))))\n","\n","\n","        return self.sigmoid(self.d6(self.pd5(self.up5(h2))))\n","\n","    def get_latent_var(self, x):\n","        mu, logvar,h5 = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n","        z = self.reparametrize(mu, logvar)\n","        return z\n","\n","    def forward(self, x):\n","        mu, logvar, h5 = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n","        z = self.reparametrize(mu, logvar)\n","        res = self.decode(z)\n","        return res, mu, logvar, h5\n","\n","class Net_A(nn.Module):\n","\n","    def __init__(self):\n","        super(Net_A,self).__init__()\n","\n","        self.ip3 = nn.Linear(2*560,2000,True)   # change the first parameter in case you change the size of the small image\n","        self.n3 = nn.BatchNorm1d(2000)\n","        self.n1 = nn.BatchNorm1d(2*560)\n","        self.ip4 = nn.Linear(2000,1000,True)\n","        self.n4 = nn.BatchNorm1d(1000)\n","        self.ip5 = nn.Linear(1000,128,True)\n","        self.n5 = nn.BatchNorm1d(128)\n","        self.ip6 = nn.Linear(128,2,True)\n","\n","    def forward(self,x):\n","        x = self.n1(x)\n","        x2 = self.ip3(x)\n","        x2 = F.relu(x2)\n","        x2 = self.n3(x2)\n","\n","        x2 = self.ip4(x2)\n","        x2 = F.relu(x2)\n","        x2 = self.n4(x2)\n","\n","        x2 = self.ip5(x2)\n","        x2 = F.relu(x2)\n","        x2 = self.n5(x2)\n","\n","        x2 = self.ip6(x2)\n","        x2 = F.relu(x2)\n","\n","\n","\n","\n","        # x2 = x2.mul(-1)\n","        # x = F.relu(x)\n","        # x = F.softmax(x,1)\n","        return x2\n","\n","\n","class Male_Female_dataset(Dataset):\n","\n","\n","   def __init__(self,root_dir,shape,transform=None):\n","     self.root_dir = root_dir\n","     self.transform = transform\n","     self.shape = shape\n","\n","   def __len__(self):\n","     return len(cele_attrib_all)\n","\n","   def __getitem__(self,idx):\n","    img1_name = os.path.join(self.root_dir,(\"{:06d}.png\".format(idx)))\n","    image1 = io.imread(img1_name)\n","    image1 = transform.resize(image1,ip_shape)\n","    #print(\"Got image 1: {0}\".format(image1))\n","\n","\n","    t = torch.rand(1)\n","    if t > 0.5:\n","        h = torch.randint(0,len(self)-5,(1,1))\n","        img2_name = os.path.join(self.root_dir,(\"{:06d}.png\".format(int(h)+1)))\n","        image2 = io.imread(img2_name)\n","        #print(\"Got image 2: {0}\".format(image2))\n","        image2 = transform.resize(image2,self.shape)\n","        image2 = torch.Tensor.float(torch.from_numpy(image2))\n","        image2 = (torch.Tensor.permute(image2,(2,0,1)))\n","        image2 = image2/256.0\n","        image1 = torch.Tensor.float(torch.from_numpy(image1))\n","        image1 = (torch.Tensor.permute(image1,(2,0,1)))\n","        image1 = image1/256.0\n","        annot = 0\n","        gender = cele_attrib_all['Male'][idx]\n","        young = cele_attrib_all['Young'][idx]\n","\n","    else:\n","        image2 = image1\n","        image2 = transform.resize(image2,self.shape)\n","        image2 = torch.Tensor.float(torch.from_numpy(image2))\n","        image2 = (torch.Tensor.permute(image2,(2,0,1)))\n","        image2 = image2/256.0\n","        image1 = torch.Tensor.float(torch.from_numpy(image1))\n","        image1 = (torch.Tensor.permute(image1,(2,0,1)))\n","        image1 = image1/256.0\n","        annot = 1\n","        gender = cele_attrib_all['Male'][idx]\n","        young = cele_attrib_all['Young'][idx]\n","\n","    sample = {'image1' : image1,\n","                'image2' : image2,\n","                'same'   : annot,\n","                'gender' : gender,\n","                'young' : young}\n","    return sample\n","\n","\n","\n","\n","reconstruction_function = nn.BCELoss()\n","reconstruction_function.size_average = False\n","\n","\n","def loss_function(recon_x, x, mu, logvar,loss1,loss2,loss_yo):\n","    BCE = reconstruction_function(recon_x, x)\n","\n","    # https://arxiv.org/abs/1312.6114 (Appendix B)\n","    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n","    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n","    KLD = torch.sum(KLD_element).mul_(-0.5)\n","\n","    return BCE + KLD +loss1- 0.0005* loss2 -0.0002*loss_yo\n","\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","print(device)\n","shape = (16,16)\n","ip_shape = (128,128)\n","train_ratio = 0.7\n","val_ratio = 0.15\n","test_ratio = 1-train_ratio-val_ratio\n","dataset = Male_Female_dataset(images_path,shape)\n","\n","\n","if load_net:\n","    model_high = VAE(nc=3, ngf=ip_shape[0], ndf=ip_shape[1], latent_variable_size=500).to(device)\n","    model_low = VAE_low(nc=3, ngf=shape[0], ndf=shape[1], latent_variable_size=60).to(device)\n","    class_net_SD = Net_A().to(device)\n","    class_net_MF = Net_A().to(device)\n","    class_net_YO = Net_A().to(device)\n","\n","    checkpoint_high = torch.load('/content/drive/MyDrive/vre_autoencoder_final/trained_modes/checkpoint_propose_Male_celeb_high.pth.tar')\n","    checkpoint_low = torch.load('/content/drive/MyDrive/vre_autoencoder_final/trained_modes/checkpoint_propose_Male_celeb_low.pth.tar')\n","    checkpoint_class_SD = torch.load('/content/drive/MyDrive/vre_autoencoder_final/trained_modes/checkpoint_classification_propose_SD.pth.tar')\n","    checkpoint_class_SD = torch.load('/content/drive/MyDrive/vre_autoencoder_final/trained_modes/checkpoint_classification_propose_MF.pth.tar')\n","    checkpoint_class_YO = torch.load('/content/drive/MyDrive/vre_autoencoder_final/trained_modes/checkpoint_classification_propose_YO.pth.tar')\n","\n","    model_high.load_state_dict ( checkpoint_high['state_dict'])\n","    model_low.load_state_dict ( checkpoint_low['state_dict'])\n","    class_net_SD.load_state_dict ( checkpoint_class_SD['state_dict'])\n","    class_net_MF.load_state_dict ( checkpoint_class_SD['state_dict'])\n","    class_net_YO.load_state_dict ( checkpoint_class_SD['state_dict'])\n","\n","    optimizer_high = optim.Adam(model_high.parameters(),lr = 0.00001, weight_decay = 0.0005)\n","    optimizer_low = optim.Adam(model_low.parameters(),lr = 0.0001, weight_decay = 0.0005)\n","    optimizer_class_SD = optim.Adam(class_net_SD.parameters(),lr = 0.0001, weight_decay = 0.0005)\n","    optimizer_class_MF = optim.Adam(class_net_SD.parameters(),lr = 0.0001, weight_decay = 0.0005)\n","    optimizer_class_YO = optim.Adam(class_net_SD.parameters(),lr = 0.0001, weight_decay = 0.0005)\n","\n","    optimizer_high.load_state_dict = checkpoint_high['optimizer']\n","    optimizer_low.load_state_dict = checkpoint_low['optimizer']\n","    optimizer_class_SD.load_state_dict = checkpoint_class_SD['optimizer']\n","    optimizer_class_MF.load_state_dict = checkpoint_class_SD['optimizer']\n","    optimizer_class_YO.load_state_dict = checkpoint_class_SD['optimizer']\n","\n","\n","\n","else:\n","    #torch.cuda.empty_cache()\n","    model_high   = VAE(nc=3, ngf=ip_shape[0], ndf=ip_shape[1], latent_variable_size=500).to(device)\n","    model_low    = VAE_low(nc=3, ngf=shape[0], ndf=shape[1], latent_variable_size=60).to(device)\n","    class_net_SD = Net_A().to(device)\n","    class_net_MF = Net_A().to(device)\n","    class_net_YO = Net_A().to(device)\n","\n","\n","    optimizer_high     = optim.Adam(model_high.parameters(),lr = 0.00001, weight_decay = 0.0005)\n","    optimizer_low      = optim.Adam(model_low.parameters(),lr = 0.00001, weight_decay = 0.0005)\n","    optimizer_class_SD = optim.Adam(class_net_SD.parameters(),lr = 0.000001, weight_decay = 0.0005)\n","    optimizer_class_MF = optim.Adam(class_net_MF.parameters(),lr = 0.000001, weight_decay = 0.0005)\n","    optimizer_class_YO = optim.Adam(class_net_YO.parameters(),lr = 0.000001, weight_decay = 0.0005)\n","\n","    checkpoint_class_SD= {'epoch':0}\n","\n","\n","\n","\n","\n","train_dataloader = DataLoader(dataset,batch_size=50,sampler = SubsetRandomSampler(index))\n","\n","err_same = []\n","err_gender = []\n","\n","acc1_SD = []\n","acc1_MF = []\n","acc1_YO = []\n","\n","\n","criterion2 = nn.CrossEntropyLoss()\n","t = -1\n","# Check if images are already exist in the folder if not then pass\n","for ep in range(checkpoint_class_SD['epoch'],5):\n","    for i,data in enumerate(train_dataloader):\n","        torch.cuda.empty_cache()\n","        optimizer_high.zero_grad()\n","        optimizer_low.zero_grad()\n","        optimizer_class_SD.zero_grad()\n","        optimizer_class_MF.zero_grad()\n","\n","        input1, input2 , label, gender ,young= data.items()\n","        input1, input2 = input1[1].to(device), input2[1].to(device)\n","        label1 = label[1].to(device)\n","        gender = gender[1].to(device)\n","        young = young[1].to(device)\n","        gender = (gender+torch.ones_like(gender).to(device))//2\n","        young = (young+torch.ones_like(young).to(device))//2\n","\n","\n","\n","        recon_batch_high, mu_high, logvar_high, h2_h = model_high(input1)\n","        recon_batch_low, mu_low, logvar_low, h2_l = model_low(input2)\n","\n","        mu_all = torch.cat((mu_high,mu_low),1)\n","        logvar_all = torch.cat((logvar_high,logvar_low),1)\n","        class_input = torch.cat((mu_all,logvar_all),1)\n","        #class_input = mu_all\n","        class_out_SD = class_net_SD(class_input)\n","        class_out_MF = class_net_MF(class_input)\n","        class_out_YO = class_net_YO(class_input)\n","\n","\n","\n","        loss_class_SD = criterion2(class_out_SD,label1)\n","        loss_class_MF = criterion2(class_out_MF,gender)\n","        loss_class_YO = criterion2(class_out_YO,young)\n","\n","        loss_high = loss_function(recon_batch_high, input1, mu_high, logvar_high,loss_class_SD,loss_class_MF,loss_class_YO)\n","        loss_low = loss_function(recon_batch_low, input2, mu_low, logvar_low,loss_class_SD,loss_class_MF,loss_class_YO)\n","\n","        loss_class_SD.backward(retain_graph=True)\n","        loss_class_MF.backward(retain_graph=True)\n","        loss_high.backward(retain_graph=True)\n","        loss_low.backward()\n","\n","\n","        optimizer_high.step()\n","        optimizer_low.step()\n","        optimizer_class_SD.step()\n","        optimizer_class_MF.step()\n","        optimizer_class_YO.step()\n","\n","\n","\n","        if (i%5==0):\n","            print (\"HQ image reconstruction loss:\",loss_high.item(),'iteration: ',i,\"epoch: \",ep)\n","            print (\"LQ image reconstruction loss:\",loss_low.item(),'iteration: ',i,\"epoch: \",ep)\n","            print (\"Same Different Classification loss:\", loss_class_SD.item(),'iteration: ',i,\"epoch: \",ep)\n","            print (\"Male Female Classification loss:\", loss_class_MF.item(),'iteration: ',i,\"epoch: \",ep)\n","            print (\"Young Classification loss:\", loss_class_YO.item(),'iteration: ',i,\"epoch: \",ep)\n","            print (\"----------------------------------------------------\")\n","\n","        if (i%50==0):\n","            val_index1 = np.random.permutation(val_index)[:100]\n","            val_dataloader = DataLoader(dataset,batch_size=100,sampler = SubsetRandomSampler(val_index1))\n","            val_iter = iter(val_dataloader)\n","\n","            total = 0\n","            correct1_SD = 0\n","            correct1_MF = 0\n","            correct1_YO = 0\n","            for j,dataj in enumerate(val_dataloader):\n","                input1j, input2j, labelj, gender, young = dataj.items()\n","                input1j, input2j = input1j[1].to(device), input2j[1].to(device)\n","\n","                labelj = labelj[1].to(device)\n","                gender = gender[1].to(device)\n","                gender = (gender+torch.ones_like(gender).to(device))//2\n","\n","                young = young[1].to(device)\n","                young = (young+torch.ones_like(young).to(device))//2\n","                recon_batch_high, mu_high, logvar_high, h2_h = model_high(input1j)\n","                recon_batch_low, mu_low, logvar_low, h2_l = model_low(input2j)\n","\n","                mu_all = torch.cat((mu_high,mu_low.data),1)\n","                logvar_all = torch.cat((logvar_high,logvar_low),1)\n","                class_input = torch.cat((mu_all,logvar_all),1)\n","                #class_input = mu_all\n","                class_out_SD = class_net_SD(class_input)\n","                class_out_MF = class_net_MF(class_input)\n","                class_out_YO = class_net_YO(class_input)\n","                _,predicted1_SD = torch.max(class_out_SD.data,1)\n","                _,predicted1_MF = torch.max(class_out_MF.data,1)\n","                _,predicted1_YO = torch.max(class_out_YO.data,1)\n","                # _,predicted2 = torch.max(output_A.data,1)\n","                total +=labelj.size(0)\n","                correct1_SD += (predicted1_SD == labelj).sum().item()\n","                correct1_MF += (predicted1_MF == gender).sum().item()\n","                correct1_YO += (predicted1_YO == young).sum().item()\n","                # correct2 += (predicted2 == gender).sum().item()\n","            print('Accuracy of SD: %d %%'%(100*correct1_SD/total))\n","            print('Accuracy of MF: %d %%'%(100*correct1_MF/total))\n","            print('Accuracy of YO: %d %%'%(100*correct1_MF/total))\n","\n","            # print('Accuracy_MF: %d %%'%(100*correct2/total))\n","\n","            acc1_SD.append(100*correct1_SD/total) #low high\n","            acc1_MF.append(100*correct1_MF/total) #low high\n","            acc1_YO.append(100*correct1_YO/total) #low high\n","            print('Mean Accuracy of SD: %d %%'%(np.mean(acc1_SD)))\n","            print('Mean Accuracy of MF: %d %%'%(np.mean(acc1_MF)))\n","            print('Mean Accuracy of YO: %d %%'%(np.mean(acc1_YO)))\n","            print(\"----------------------------------------------------\")\n","            # acc2.append(100*correct2/total) # male female\n","    save_checkpoint_class_SD({\n","            'epoch': ep + 1,\n","            'state_dict': class_net_SD.state_dict(),\n","\n","            'optimizer' : optimizer_class_SD.state_dict(),\n","        })\n","    save_checkpoint_class_MF({\n","            'epoch': ep + 1,\n","            'state_dict': class_net_MF.state_dict(),\n","\n","            'optimizer' : optimizer_class_MF.state_dict(),\n","        })\n","    save_checkpoint_class_YO({\n","            'epoch': ep + 1,\n","            'state_dict': class_net_YO.state_dict(),\n","\n","            'optimizer' : optimizer_class_YO.state_dict(),\n","        })\n","    save_checkpoint_high({\n","            'epoch': ep + 1,\n","            'state_dict': model_high.state_dict(),\n","\n","            'optimizer' : optimizer_high.state_dict(),\n","        })\n","    save_checkpoint_low({\n","            'epoch': ep + 1,\n","            'state_dict': model_low.state_dict(),\n","\n","            'optimizer' : optimizer_low.state_dict(),\n","        })\n","\n","dataset.__getitem__(1)\n","\n","cele_attrib['Male'][1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jgTSR6Jwb6Us"},"outputs":[],"source":["import numpy as np\n","\n","val_index1 = np.random.permutation(val_index)[:100]\n","val_dataloader = DataLoader(dataset,batch_size=50,sampler = SubsetRandomSampler(test_index))\n","val_iter = iter(val_dataloader)\n","predicted_lables = []\n","real_labels_g = []\n","predicted_lables_g = []\n","real_labels = []\n","real_labels_y = []\n","predicted_lables_y = []\n","\n","total = 0\n","correct1_SD = 0\n","correct1_MF = 0\n","correct1_YO = 0\n","acc1=[]\n","acc2=[]\n","acc1_YO = []\n","for j,dataj in enumerate(val_dataloader):\n","            input1, input2 , label, gender ,young= dataj.items()\n","            input1, input2 = input1[1].to(device), input2[1].to(device)\n","            labelj = label[1].to(device)\n","            gender = gender[1].to(device)\n","            young = young[1].to(device)\n","            gender = (gender+torch.ones_like(gender).to(device))//2\n","            young = (young+torch.ones_like(young).to(device))//2\n","\n","            mu_all = torch.cat((mu_high,mu_low.data),1)\n","            logvar_all = torch.cat((logvar_high,logvar_low),1)\n","            class_input = torch.cat((mu_all,logvar_all),1)\n","            #class_input = mu_all\n","            class_out_SD = class_net_SD(class_input)\n","            class_out_MF = class_net_MF(class_input)\n","            class_out_YO = class_net_YO(class_input)\n","            _,predicted1_SD = torch.max(class_out_SD.data,1)\n","            _,predicted1_MF = torch.max(class_out_MF.data,1)\n","            _,predicted1_YO = torch.max(class_out_YO.data,1)\n","            # _,predicted2 = torch.max(output_A.data,1)\n","            total +=labelj.size(0)\n","            correct1_SD += (predicted1_SD == labelj).sum().item()\n","            correct1_MF += (predicted1_MF == gender).sum().item()\n","            correct1_YO += (predicted1_YO == young).sum().item()\n","            predicted_lables.append(torch.Tensor.numpy(predicted1_SD.cpu()))\n","            real_labels.append(torch.Tensor.numpy(labelj.cpu()))\n","\n","            predicted_lables_g.append(torch.Tensor.numpy(predicted1_MF.cpu()))\n","            real_labels_g.append(torch.Tensor.numpy(gender.cpu()))\n","            predicted_lables_y.append(torch.Tensor.numpy(predicted1_YO.cpu()))\n","            real_labels_y.append(torch.Tensor.numpy(young.cpu()))\n","\n","            # correct2 += (predicted2 == gender).sum().item()\n","            print('Accuracy of SD: %d %%'%(100*correct1_SD/total))\n","            print('Accuracy of MF: %d %%'%(100*correct1_MF/total))\n","            print('Accuracy of YO: %d %%'%(100*correct1_YO/total))\n","\n","           \n","            acc1.append(100*correct1_SD/total)\n","            acc2.append(100*correct1_MF/total)\n","            acc1_YO.append(100*correct1_YO/total)\n","            print(mt.confusion_matrix(np.array(real_labels).flatten(),np.array(predicted_lables).flatten()))\n","            \n","            print(mt.confusion_matrix(np.array(real_labels_g).flatten(),np.array(predicted_lables_g).flatten()))\n","            print(mt.confusion_matrix(np.array(real_labels_y).flatten(),np.array(predicted_lables_y).flatten()))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"gt_3rkSOPm37"},"outputs":[],"source":["print(young)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyPHwLAUJOoOKDChRvyierPZ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}